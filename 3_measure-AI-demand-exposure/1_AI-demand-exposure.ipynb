{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdd08ed2-e991-4aaa-aa6f-d0b6dc718882",
   "metadata": {},
   "source": [
    "# 4-2. Construct AI Demand Exposure Score - PART 1: Task Extraction\n",
    "\n",
    "Job posting data is provided by: https://www.kaggle.com/datasets/arshkon/linkedin-job-postings\n",
    "\n",
    "**Author:** Yu Kyung Koh\n",
    "\n",
    "**Last Updated:** 2025/06/15\n",
    "\n",
    "---\n",
    "\n",
    "### General Goals:\n",
    "* Construct AI Demand Exposure Score, which measures how susceptible job tasks listed in new postings are to augmentation or replacement by AI\n",
    "* I am going to follow the approach in 2025 Revelio Labs report \"AI at Work: The State of AI Adoption in 2025\"\n",
    "\n",
    "### In this code:\n",
    "* As noted in the preparatory step (Code 4-1), I found that **Ollama** is the most effective tool for extracting job tasks given my resource constraints.\n",
    "     * => Here, I apply Ollama to a larger set of job postings, focusing on specific job categories such as data-related roles, consulting, finance, and others.\n",
    "* ‼️ However, it is **computationally infeasible** to apply Ollama to all 30,000 job postings.\n",
    "  * The estimated runtime is approximately 8 days (30 seconds for each posting), even for this relatively small datset.\n",
    "* To address this, I combine **LLM-based** extraction with a **machine learning classifier** to scale up task extraction across the full dataset efficiently:\n",
    "  * **Step 1:** Use **Mistral via Ollama** to extract tasks from 100 job postings per job category.\n",
    "  * **Step 2:** Convert the extracted outputs into sentence-level **training data**, labeling sentences as task-related or not.\n",
    "  * **Step 3:** Train a lightweight and fast classifier (e.g., **DistilBERT**) to distinguish task sentences.\n",
    "  * **Step 4:** For the full dataset, split job postings into individual sentences\n",
    "  * **Step 5:** Apply the trained classifier to each sentence to identify task-related content at scale.\n",
    "\n",
    "### Note:\n",
    "* Before running this code, I need to type \"ollama run mistral\" in the terminal\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b868a754-606a-419b-8238-579e5a6dd1da",
   "metadata": {},
   "source": [
    "## SECTION 1: Bring in the job posting data \n",
    "\n",
    "Here, I am going to focus on the smaller set of job posting data cleaned from code 2-1. \n",
    "\n",
    "This data only contains job posting for few job categories, including data-related jobs, consultants, software enginners, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08e0a12e-e013-410f-a600-d49f11b72a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import math\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#from rapidfuzz import process, fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "327fe73d-28b4-4b53-b322-05aba0189af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29724"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import cleaned data from Code 2-1\n",
    "cleandatadir = '/Users/yukyungkoh/Desktop/1_Post-PhD/7_Python-projects/2_practice-NLP_job-posting_NEW/2_data/cleaned_data'\n",
    "jobdata = os.path.join(cleandatadir, '1_job-posting_jobs-categorized_df.pkl')\n",
    "jobs_df = pd.read_pickle(jobdata, 'zip')\n",
    "#jobs_df = joblib.load(jobdata)\n",
    "\n",
    "## Check how many job postings are in this data \n",
    "len(jobs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6b9819e-38b5-4051-bb5d-edfcd9e8a5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>title</th>\n",
       "      <th>work_type</th>\n",
       "      <th>normalized_salary</th>\n",
       "      <th>combined_desc</th>\n",
       "      <th>job_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>921716</td>\n",
       "      <td>Corcoran Sawyer Smith</td>\n",
       "      <td>Marketing Coordinator</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>38480.0</td>\n",
       "      <td>Job descriptionA leading real estate firm in N...</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10998357</td>\n",
       "      <td>The National Exemplar</td>\n",
       "      <td>Assitant Restaurant Manager</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>The National Exemplar is accepting application...</td>\n",
       "      <td>Other Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>56482768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Appalachian Highlands Women's Business Center</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FULL JOB DESCRIPTION – PROGRAM DIRECTOR Appala...</td>\n",
       "      <td>Business/Finance Job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>69333422</td>\n",
       "      <td>Staffing Theory</td>\n",
       "      <td>Senior Product Marketing Manager</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A leading pharmaceutical company committed to ...</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>111513530</td>\n",
       "      <td>United Methodists of Greater New Jersey</td>\n",
       "      <td>Content Writer, Communications</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Application opening date: April 24, 2024\\nTitl...</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id                             company_name  \\\n",
       "0      921716                    Corcoran Sawyer Smith   \n",
       "2    10998357                   The National Exemplar    \n",
       "12   56482768                                      NaN   \n",
       "14   69333422                          Staffing Theory   \n",
       "18  111513530  United Methodists of Greater New Jersey   \n",
       "\n",
       "                                            title  work_type  \\\n",
       "0                           Marketing Coordinator  FULL_TIME   \n",
       "2                     Assitant Restaurant Manager  FULL_TIME   \n",
       "12  Appalachian Highlands Women's Business Center  FULL_TIME   \n",
       "14               Senior Product Marketing Manager  FULL_TIME   \n",
       "18                 Content Writer, Communications  FULL_TIME   \n",
       "\n",
       "    normalized_salary                                      combined_desc  \\\n",
       "0             38480.0  Job descriptionA leading real estate firm in N...   \n",
       "2             55000.0  The National Exemplar is accepting application...   \n",
       "12                NaN  FULL JOB DESCRIPTION – PROGRAM DIRECTOR Appala...   \n",
       "14                NaN  A leading pharmaceutical company committed to ...   \n",
       "18                NaN  Application opening date: April 24, 2024\\nTitl...   \n",
       "\n",
       "            job_category  \n",
       "0              Marketing  \n",
       "2          Other Manager  \n",
       "12  Business/Finance Job  \n",
       "14             Marketing  \n",
       "18             Marketing  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c7b3935-772a-4a81-aad6-52d375e16554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_category\n",
       "Other Manager              13385\n",
       "Business/Finance Job        4557\n",
       "Product/Project Manager     3400\n",
       "Marketing                   2598\n",
       "Software/Developer          1994\n",
       "Data-related                1946\n",
       "Consultant                  1844\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df['job_category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b14cef-2ecd-4849-adba-589a4f885d80",
   "metadata": {},
   "source": [
    "---\n",
    "## SECTION 2: Use **Mistral via Ollama** to extract tasks from 100 job postings per job category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71457479-418b-4885-aa18-92315fefc8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_category\n",
      "Business/Finance Job       100\n",
      "Consultant                 100\n",
      "Data-related               100\n",
      "Marketing                  100\n",
      "Other Manager              100\n",
      "Product/Project Manager    100\n",
      "Software/Developer         100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from ollama import chat\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------------------------\n",
    "# STEP 1: Sample 100 job postings per category\n",
    "# -------------------------------------\n",
    "sampled_jobs = []\n",
    "\n",
    "for category, group in jobs_df.groupby(\"job_category\"):\n",
    "    if len(group) >= 100:\n",
    "        sampled = group.sample(n=100, random_state=42)\n",
    "    else:\n",
    "        sampled = group\n",
    "    sampled_jobs.append(sampled)\n",
    "\n",
    "sampled_jobs_df = pd.concat(sampled_jobs).reset_index(drop=True)\n",
    "\n",
    "# Show sample sizes per category\n",
    "print(sampled_jobs_df[\"job_category\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c02bdcb0-4e46-42fe-b4fa-709ff8acddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -------------------------------------------------------\n",
    "## STEP 2: Pre-process each job posting -> For better task extraction and matching \n",
    "## -------------------------------------------------------\n",
    "import re\n",
    "\n",
    "def preprocess_job_posting(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # (1) Fix missing space between uppercase word and capitalized word (e.g., \"CRMMust\" → \"CRM Must\")\n",
    "    text = re.sub(r\"([A-Z]{2,})([A-Z][a-z])\", r\"\\1 \\2\", text)\n",
    "\n",
    "    # (2) Fix missing space after periods or sentence breaks (e.g., \"position.Responsibilities\" → \"position. Responsibilities\")\n",
    "    text = re.sub(r\"([a-zA-Z])([.!?])([A-Z])\", r\"\\1\\2 \\3\", text)\n",
    "\n",
    "    # (3) Normalize bullets/dashes to line breaks (for LLM chunking and clarity)\n",
    "    text = re.sub(r\"[•\\-–—]\", \"\\n- \", text)\n",
    "\n",
    "    # (4) Collapse repeated newlines or whitespace\n",
    "    text = re.sub(r\"\\n{2,}\", \"\\n\", text)\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "sampled_jobs_df[\"cleaned_desc\"] = sampled_jobs_df[\"combined_desc\"].apply(preprocess_job_posting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff065d2-ed96-4a83-9b75-b8f08f94da5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# STEP 3: Define LLM Task Extraction Function\n",
    "# --------------------------------------------------\n",
    "def extract_tasks_from_posting(posting_text):\n",
    "    if not isinstance(posting_text, str) or not posting_text.strip():\n",
    "        return \"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "            Your task is to extract **only job tasks or responsibilities** from the job posting below.\n",
    "            \n",
    "            🚫 Do NOT paraphrase or summarize.  \n",
    "            ✅ You MUST copy the exact sentences or phrases directly from the job posting.  \n",
    "            ✅ Your output must consist only of bullet points copied **verbatim** from the original text.  \n",
    "            ✅ Do not rewrite or reword anything.\n",
    "            \n",
    "            Only include statements that describe **what the employee will do** in the role.\n",
    "            \n",
    "            ❌ DO NOT include:\n",
    "            - Skills or qualifications (e.g., \"must have X years experience\")\n",
    "            - Company mission or benefits\n",
    "            - Legal disclaimers or EEO statements (e.g. CyberCoders is an equal opportunity employer)\n",
    "            - Location or salary information (e.g. Must be living in CA to be considered for position)\n",
    "            \n",
    "            ✅ DO include:\n",
    "            - Specific responsibilities, duties, and tasks\n",
    "            - Only if they are stated as actions the employee is expected to perform\n",
    "            \n",
    "            ---\n",
    "            \n",
    "            **Job Posting:**\n",
    "            \n",
    "            {posting_text}\n",
    "            \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = chat(\n",
    "            model='mistral',\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response['message']['content'].strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"ERROR: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c30e8934-2ef5-4f83-bb0d-811594651390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 700/700 [5:28:39<00:00, 28.17s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------------\n",
    "# STEP 4: Run task extraction with progress bar\n",
    "# -------------------------------------\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from multiprocessing import cpu_count\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Limit threads to 1–2 to avoid choking Ollama\n",
    "NUM_THREADS = 2\n",
    "\n",
    "# Create a thread pool and extract tasks\n",
    "with ThreadPool(NUM_THREADS) as pool:\n",
    "    # Use tqdm with manual update\n",
    "    extracted_tasks = []\n",
    "    for task in tqdm(pool.imap(extract_tasks_from_posting, sampled_jobs_df[\"cleaned_desc\"]), total=len(sampled_jobs_df)):\n",
    "        extracted_tasks.append(task)\n",
    "    ## => Takes 4 hours 35 min to run\n",
    "\n",
    "# Store results\n",
    "sampled_jobs_df[\"extracted_tasks\"] = extracted_tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f726f62-f6d0-4781-a990-f7267c1751f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Task extraction complete. File saved as 'sampled_jobs_with_tasks.json'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------------\n",
    "# STEP 5: Save the result for later steps\n",
    "# -------------------------------------\n",
    "file_path = os.path.join(cleandatadir, \"sampled_jobs_with_tasks.json\")\n",
    "sampled_jobs_df.to_json(file_path, orient=\"records\", lines=True, force_ascii=False)\n",
    "\n",
    "print(\"✅ Task extraction complete. File saved as 'sampled_jobs_with_tasks.json'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1907b199-cad7-4331-8c45-f6ec67669370",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## SECTION 3: Convert to Sentence-Level Training Data\n",
    "\n",
    "**Goal:** I want to get a dataset of (sentence, is_task) pairs.\n",
    "\n",
    "**Steps:**\n",
    "1. Tokenize each job posting into sentences:\n",
    "2. Label sentences using the LLM-generated tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0243a94-9534-47ef-a2fe-46374a4ff1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bring in the sampled jobs with extracted tasks \n",
    "sampled_jobs_dir = os.path.join(cleandatadir, \"sampled_jobs_with_tasks.json\")\n",
    "sampled_jobs_df = pd.read_json(sampled_jobs_dir, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfae9ac0-05cb-4e85-bd74-46b098025b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>title</th>\n",
       "      <th>work_type</th>\n",
       "      <th>normalized_salary</th>\n",
       "      <th>combined_desc</th>\n",
       "      <th>job_category</th>\n",
       "      <th>cleaned_desc</th>\n",
       "      <th>extracted_tasks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3887576060</td>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>Sr VP of Business Development - Solar</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>185000.0</td>\n",
       "      <td>If you are a Sr VP of Business Development - S...</td>\n",
       "      <td>Business/Finance Job</td>\n",
       "      <td>If you are a Sr VP of Business Development \\n-...</td>\n",
       "      <td>- Plan and implement both short- and long-rang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3901377608</td>\n",
       "      <td>Iris Software Inc.</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>CONTRACT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Iris's client, a large insurance company, is c...</td>\n",
       "      <td>Business/Finance Job</td>\n",
       "      <td>Iris's client, a large insurance company, is c...</td>\n",
       "      <td>- Analyze business processes\\n- Anticipate req...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3865441576</td>\n",
       "      <td>Ryan RPO (Recruitment Process Outsourcing)</td>\n",
       "      <td>Remote Business Development Associate</td>\n",
       "      <td>CONTRACT</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>Profit Share Opportunity\\nCompany DescriptionR...</td>\n",
       "      <td>Business/Finance Job</td>\n",
       "      <td>Profit Share Opportunity\\nCompany DescriptionR...</td>\n",
       "      <td>- Identify and acquire new clients\\n- Prospect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3901351059</td>\n",
       "      <td>Crypto Tutors</td>\n",
       "      <td>Business Development Specialist</td>\n",
       "      <td>PART_TIME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We are looking for someone who can Execute! Ca...</td>\n",
       "      <td>Business/Finance Job</td>\n",
       "      <td>We are looking for someone who can Execute! Ca...</td>\n",
       "      <td>- Execute tasks\\n- Type fast\\n- Cold call\\n- E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3884846848</td>\n",
       "      <td>Autodesk</td>\n",
       "      <td>Business Development Representative</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Job Requisition ID #\\n\\n24WD76028\\n\\nPosition ...</td>\n",
       "      <td>Business/Finance Job</td>\n",
       "      <td>Job Requisition ID #\\n24WD76028\\nPosition Over...</td>\n",
       "      <td>- Complete weekly activities to meet sales per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id                                company_name  \\\n",
       "0  3887576060                                 CyberCoders   \n",
       "1  3901377608                          Iris Software Inc.   \n",
       "2  3865441576  Ryan RPO (Recruitment Process Outsourcing)   \n",
       "3  3901351059                               Crypto Tutors   \n",
       "4  3884846848                                    Autodesk   \n",
       "\n",
       "                                   title  work_type  normalized_salary  \\\n",
       "0  Sr VP of Business Development - Solar  FULL_TIME           185000.0   \n",
       "1                       Business Analyst   CONTRACT                NaN   \n",
       "2  Remote Business Development Associate   CONTRACT            90000.0   \n",
       "3        Business Development Specialist  PART_TIME                NaN   \n",
       "4    Business Development Representative  FULL_TIME                NaN   \n",
       "\n",
       "                                       combined_desc          job_category  \\\n",
       "0  If you are a Sr VP of Business Development - S...  Business/Finance Job   \n",
       "1  Iris's client, a large insurance company, is c...  Business/Finance Job   \n",
       "2  Profit Share Opportunity\\nCompany DescriptionR...  Business/Finance Job   \n",
       "3  We are looking for someone who can Execute! Ca...  Business/Finance Job   \n",
       "4  Job Requisition ID #\\n\\n24WD76028\\n\\nPosition ...  Business/Finance Job   \n",
       "\n",
       "                                        cleaned_desc  \\\n",
       "0  If you are a Sr VP of Business Development \\n-...   \n",
       "1  Iris's client, a large insurance company, is c...   \n",
       "2  Profit Share Opportunity\\nCompany DescriptionR...   \n",
       "3  We are looking for someone who can Execute! Ca...   \n",
       "4  Job Requisition ID #\\n24WD76028\\nPosition Over...   \n",
       "\n",
       "                                     extracted_tasks  \n",
       "0  - Plan and implement both short- and long-rang...  \n",
       "1  - Analyze business processes\\n- Anticipate req...  \n",
       "2  - Identify and acquire new clients\\n- Prospect...  \n",
       "3  - Execute tasks\\n- Type fast\\n- Cold call\\n- E...  \n",
       "4  - Complete weekly activities to meet sales per...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_jobs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b7188af-0463-4232-91b0-7b1ac3bda59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sampled_jobs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b2f4dc4-f637-47e2-bd9e-d6125096330f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n## -------------------------------------------------------\\n## STEP 1: Tokenize each job posting into sentences\\n## -------------------------------------------------------\\nimport nltk\\nnltk.download(\\'punkt_tab\\')\\nfrom nltk.tokenize import sent_tokenize\\n\\n# Tokenize into sentence lists\\nsampled_jobs_df[\"sentence_list\"] = sampled_jobs_df[\"combined_desc\"].apply(sent_tokenize)\\n\\n# Explode into a new sentence-level DataFrame\\nsentence_df = sampled_jobs_df[[\"job_id\", \"job_category\", \"extracted_tasks\", \"sentence_list\"]].explode(\"sentence_list\")\\nsentence_df = sentence_df.rename(columns={\"sentence_list\": \"sentence\"})\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "## -------------------------------------------------------\n",
    "## STEP 1: Tokenize each job posting into sentences\n",
    "## -------------------------------------------------------\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Tokenize into sentence lists\n",
    "sampled_jobs_df[\"sentence_list\"] = sampled_jobs_df[\"combined_desc\"].apply(sent_tokenize)\n",
    "\n",
    "# Explode into a new sentence-level DataFrame\n",
    "sentence_df = sampled_jobs_df[[\"job_id\", \"job_category\", \"extracted_tasks\", \"sentence_list\"]].explode(\"sentence_list\")\n",
    "sentence_df = sentence_df.rename(columns={\"sentence_list\": \"sentence\"})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98d2f390-dbc2-403e-b185-ee31966aff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3ad6a6d-fd48-4291-af55-dd658ada52f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(sentence_df)  ## Each row contains each sentence of the job posting. Hence, sample size is much larger than the original sampled_job_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7360855c-50cc-4ee5-b33c-992480582c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n## -------------------------------------------------------\\n## STEP 2: Label sentences using the LLM-generated tasks\\n## -------------------------------------------------------\\n## Note that extracted tasks may not be exactly same as the original sentences, \\n## due to paraphrasing, rewording etc. \\n## Therefore, I need to match each sentence to extracted tasks using the embedding approach. \\n## If I use the exact string match instead, it may miss most valid mathes\\n\\nfrom sentence_transformers import SentenceTransformer, util\\nimport torch\\nfrom tqdm import tqdm\\n\\n# Load a fast and effective model\\nmodel = SentenceTransformer(\\'all-MiniLM-L6-v2\\')  # 384-dim embeddings, very fast\\n\\n# Function to compute label using cosine similarity\\ndef label_with_embeddings(sentence, extracted_tasks, threshold=0.7):\\n    # (1) Input validation: Check if extracted_tasks is missing or sentence is black \\n    if not isinstance(extracted_tasks, str) or not sentence.strip():\\n        return 0\\n\\n    # (2) Clean and tokenize extracted task \\n    #     Splits the extracted tasks (usually a bullet-point list) by newlines into a list of clean task strings.\\n    task_lines = [line.strip() for line in extracted_tasks.split(\\'\\n\\') if line.strip()]\\n    if not task_lines:\\n        return 0\\n\\n    # (3) Compute sentence and task embeddings \\n    #     => Converts both the sentence and all task lines into embedding vectors\\n    sentence_emb = model.encode(sentence, convert_to_tensor=True)\\n    task_embs = model.encode(task_lines, convert_to_tensor=True)\\n\\n    # (4) Compute similarity\\n    #     => Computes cosine similarity between the sentence and each extracted task \\n    #        Output is a tensor of similarity scores (e.g. [0.23, 0.88, 0.42, ...]) \\n    similarities = util.cos_sim(sentence_emb, task_embs)[0]\\n\\n    # Return 1 if \\n    return int(torch.max(similarities) >= threshold)\\n\\n# Apply with progress bar\\ntqdm.pandas(desc=\"Labeling sentences using embeddings\")\\nsentence_df[\"label\"] = sentence_df.progress_apply(\\n    lambda row: label_with_embeddings(row[\"sentence\"], row[\"extracted_tasks\"]), axis=1\\n)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "## -------------------------------------------------------\n",
    "## STEP 2: Label sentences using the LLM-generated tasks\n",
    "## -------------------------------------------------------\n",
    "## Note that extracted tasks may not be exactly same as the original sentences, \n",
    "## due to paraphrasing, rewording etc. \n",
    "## Therefore, I need to match each sentence to extracted tasks using the embedding approach. \n",
    "## If I use the exact string match instead, it may miss most valid mathes\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load a fast and effective model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # 384-dim embeddings, very fast\n",
    "\n",
    "# Function to compute label using cosine similarity\n",
    "def label_with_embeddings(sentence, extracted_tasks, threshold=0.7):\n",
    "    # (1) Input validation: Check if extracted_tasks is missing or sentence is black \n",
    "    if not isinstance(extracted_tasks, str) or not sentence.strip():\n",
    "        return 0\n",
    "\n",
    "    # (2) Clean and tokenize extracted task \n",
    "    #     Splits the extracted tasks (usually a bullet-point list) by newlines into a list of clean task strings.\n",
    "    task_lines = [line.strip() for line in extracted_tasks.split('\\n') if line.strip()]\n",
    "    if not task_lines:\n",
    "        return 0\n",
    "\n",
    "    # (3) Compute sentence and task embeddings \n",
    "    #     => Converts both the sentence and all task lines into embedding vectors\n",
    "    sentence_emb = model.encode(sentence, convert_to_tensor=True)\n",
    "    task_embs = model.encode(task_lines, convert_to_tensor=True)\n",
    "\n",
    "    # (4) Compute similarity\n",
    "    #     => Computes cosine similarity between the sentence and each extracted task \n",
    "    #        Output is a tensor of similarity scores (e.g. [0.23, 0.88, 0.42, ...]) \n",
    "    similarities = util.cos_sim(sentence_emb, task_embs)[0]\n",
    "\n",
    "    # Return 1 if \n",
    "    return int(torch.max(similarities) >= threshold)\n",
    "\n",
    "# Apply with progress bar\n",
    "tqdm.pandas(desc=\"Labeling sentences using embeddings\")\n",
    "sentence_df[\"label\"] = sentence_df.progress_apply(\n",
    "    lambda row: label_with_embeddings(row[\"sentence\"], row[\"extracted_tasks\"]), axis=1\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71220565-7ba3-49f1-9216-5ec377aba9f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py310-nlp]",
   "language": "python",
   "name": "conda-env-py310-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
