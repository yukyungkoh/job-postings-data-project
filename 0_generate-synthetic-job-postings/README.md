# Synthetic U.S. Job Posting Data Generation

This folder contains code and documentation for generating large-scale **synthetic job posting data** using OpenAI's GPT-4o model. The goal is to simulate realistic job titles and descriptions across a wide range of industries, with variation in job content, seniority, formatting, and style ‚Äî mimicking the richness and messiness of real-world job postings.

---

## üéØ Why Generate Synthetic Job Postings?

Access to clean, labeled, and representative job posting data is often restricted by licensing or availability. 

Synthetic data provides a scalable alternative for:

- **Prototyping NLP pipelines** for skill extraction, job classification, and labor market analytics  
- **Exploring labor demand trends** (e.g., remote work prevalence, DEI language, seniority levels)
- **Training and benchmarking models** for occupational taxonomies or recruiter tools  
- Supporting **economics and labor market research** without proprietary data constraints  

---

## ‚öôÔ∏è How It Works

The system uses OpenAI‚Äôs GPT-4o-mini via asynchronous API calls to generate postings in batches.

### Key Features:

- **Diverse job sectors** (e.g. healthcare, tech, education, retail)
- **Natural variation in job titles**: includes/omits seniority, certifications, tools, location, and abbreviations (e.g., ‚ÄúSr.‚Äù vs. ‚ÄúSenior‚Äù)
- **Structured and unstructured content**: mix of paragraphs and bullet points
- **Realistic seniority-based job content**:
  - Entry-level: minimal experience, welcoming tone
  - Mid-level: 2‚Äì5 years experience, broader responsibilities
  - Senior-level: leadership duties, advanced qualifications
- **Random inclusion of**: DEI language, compensation info, and benefits

---

## üß† Prompt Design Philosophy

Prompt engineering is designed to simulate **how job postings appear on platforms like LinkedIn or Indeed**, including inconsistencies in:

- Title formatting  
- Language specificity  
- Role expectations  
- Presence or absence of structured metadata

This is important for downstream use cases like skill extraction, wage imputation, and occupation classification.

---


---

## üß™ Example Use Cases

You can use this synthetic dataset to:

- Train a **job-skill extractor** using named entity recognition
- Classify job postings by **occupation, industry, or remote status**
- Analyze patterns in **seniority, DEI language, or benefits offered**
- Prototype **task-level embeddings** or job similarity models

---

## üìå Caveats

- The data is **synthetic** ‚Äî generated by a large language model and not scraped from actual job boards.
- Some repetition and unrealistic phrasing may occur, though prompt tuning reduces this.
- This dataset is not suitable for production-grade labor market insights, but is valuable for **methodological research and model development**.



